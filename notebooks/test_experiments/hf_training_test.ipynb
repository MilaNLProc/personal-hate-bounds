{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2738dbcc-5233-4ac0-b79e-96a4c4857739",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoConfig, PretrainedConfig, RobertaForSequenceClassification\n",
    "from transformers.models.roberta.modeling_roberta import RobertaClassificationHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d62046-ac0d-4bf2-9083-f185ec8ca86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"yelp_review_full\", split='train[:100]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9178628b-6392-4d8a-a51c-2aa10dc8bcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb251c0-5a2e-4314-ba93-88531ba088a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'roberta-base'\n",
    "\n",
    "# Config for the encoder.\n",
    "roberta_classifier_config = AutoConfig.from_pretrained(\n",
    "    model_id,\n",
    "    finetuning_task=\"text-classification\",\n",
    "    id2label={\n",
    "        i: label\n",
    "        for i, label in enumerate(range(5))\n",
    "    },\n",
    "    label2id={\n",
    "        label: i\n",
    "        for i, label in enumerate(range(5))\n",
    "    }\n",
    ")\n",
    "\n",
    "# Config for the classification head. These are all the\n",
    "# parameters a `RobertaClassificationHead` requires.\n",
    "roberta_classification_head_config = PretrainedConfig()\n",
    "\n",
    "roberta_classification_head_config.classifier_dropout = 0.1\n",
    "roberta_classification_head_config.hidden_size = 64\n",
    "roberta_classification_head_config.num_labels = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971512b9-9d42-40d3-8204-75d1fadf6e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate tokenizer.\n",
    "roberta_tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "# Instantiate RoBERTa model.\n",
    "roberta_classifier = RobertaForSequenceClassification.from_pretrained(\n",
    "    'roberta-base',\n",
    "    config=roberta_classifier_config,\n",
    ")\n",
    "\n",
    "# Substitute the default classification head with a custom one.\n",
    "classification_head = RobertaClassificationHead(roberta_classification_head_config)\n",
    "classification_head.dense = torch.nn.Linear(\n",
    "    roberta_classifier.config.hidden_size,  # The `in_features` parameter must be equal to the encoder's hidden size.\n",
    "    roberta_classification_head_config.hidden_size,\n",
    ")\n",
    "\n",
    "roberta_classifier.classifier = classification_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1e5d64-0d9a-40b4-a896-1bc8807ed882",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return roberta_tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f365b89-660b-4ed9-ad8e-cacf425787bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a78f68-4d13-49a7-a435-c3bca46e2124",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa96f1c-63b0-4be0-a0e0-992737e3c13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf2db22-cfe9-409b-b3c8-53a4b039b0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0403cea2-b222-4d27-98b4-ad7db7031bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = transformers.Trainer(\n",
    "    model=roberta_classifier,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets,\n",
    "    # eval_dataset=tokenized_datasets[\"test\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579c3423-fba2-4f60-b035-20a7306143d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52a59cb-5c79-4566-bab6-5985cc6ce69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
